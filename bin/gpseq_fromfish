#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# ------------------------------------------------------------------------------
# 
# MIT License
# 
# Copyright (c) 2017 Gabriele Girelli
# 
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
# 
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
# 
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
# 
# ------------------------------------------------------------------------------

# ------------------------------------------------------------------------------
# 
# Author: Gabriele Girelli
# Email: gigi.ga90@gmail.com
# Version: 4.1.4
# Date: 20170718
# Project: GPSeq
# Description: Calculate radial position of dots in cells
# 
# Changelog:
#  v4.1.4 - 20180313: compartment volume data exported separately.
#  					  Fixed compartment assignment.
#  					  Allowed for user-specifided pole compartment definition.
#  v4.1.3 - 20180308: added compartment volume data.
#  v4.1.2 - 20180306: fixed warning from pandas.
#  					  Removed tiff format from png masks.
#  v4.1.1 - 20180305: fixed NaN issue in cell IDs.
#  v4.1.0 - 20180302: added compatibility to compressed tiff files.
#  v4.0.1 - 20180301: fixed rotation order.
#  v4.0.0 - 20180301: added compartmentalization for ellipsoidal nuclei.
#                     Default cell values is now standardize to NaN.
#  v3.4.2 - 20180226: now enforcing round integer coordinates.
#  v3.4.1 - 20180226: fixed bug occurring when mask folder was not provided.
#  v3.4.0 - 20180220: segmented cells as additional input.
#  v3.3.0 - 20180219: input can now be already binarized.
#  v3.2.2 - 20180207: set angle to 0 when one point overlaps to the nucleus CoM.
#  v3.2.1 - 20180207: discarding rows from input table for skipped FoVs.
#  v3.2.0 - 20171212: fixed G1 selection in output table.
#  v3.1.1 - 20171206: fixed allele polarity, using correct center of mass.
#  v3.1.0 - 20171204: fixed allele polarity including aspect ratio.
#  v3.0.1 - 20171130: adjusted allele polarity, fixed selection,
#                     also now allowing missing images.
#  v3.0.0 - 20171120: changed dilation to allow anisotropic images.
#  v2.3.1 - 20171120: fixed dilation factor (now corresponds to number of px).
#  v2.3.0 - 20171120: fixed allele angle calculation and minor bug.
#  v2.2.1 - 20171116: fixed series ID issue, added version column.
#  v2.2.0 - 20171116: added polarity calculation between alleles.
#  v2.1.0 - 20171115: fixed distance calculation and normalization.
#  v2.0.0 - 20171114: fixed cell assignment and G1 selection.
#  v1.2.0 - 20171105: dilation, allele labeling, parallelization.
#  v1.1.1 - 20171020: fixed parameter description.
#  v1.1.0 - 20170830: added G1 cells selection.
#  v1.0.0 - 20170718: first implementation.
# 
# ------------------------------------------------------------------------------



# DEPENDENCIES =================================================================

import matplotlib
matplotlib.use('ps')
import matplotlib.lines as mlines
import matplotlib.pyplot as plt

import argparse
from joblib import Parallel, delayed
import math
import multiprocessing
import numpy as np
import os
import pandas as pd
import pickle
import sys
import tifffile

from scipy.ndimage.measurements import center_of_mass
from scipy.ndimage.morphology import distance_transform_edt

from skimage import draw
import skimage.io as io
from skimage.measure import label
from skimage.morphology import dilation, cube

import pygpseq as gp
from pygpseq.anim.nucleus import Nucleus
from pygpseq.tools import image as imt
from pygpseq.tools import io as iot
from pygpseq.tools import plot
from pygpseq.tools import stat as stt

# PARAMETERS ===================================================================

# Add script description
parser = argparse.ArgumentParser(description = '''
Calculate radial position of dots in cells.

The G1 selection is actually a selection of the most represented cell sub-
-population based on flatten area and integral of DNA stain intensity. In other
words, it will selected the most represented cell cycle phase in your cell
population (generally, G1). Images are expected to follow DOTTER filename
notation: "channel_series.tif".

If you already segmented your images (i.e., produced masks), provide the path to
the folder containing the masks using -m, and the prefix for the mask name with
-m. For example, with '-m /ex/mask_dir/ -M mask_', in the case of the image
file '1.tif', the script will look for the mask at "/ex/mask_dir/mask_1.tif".
If the mask can be found, it will be used, otherwise it will be generated and
then saved. This can be used also to export masks as tifs to the folder
specified with -m.

If your cells have ellipsoidal shape, use the --annotate-compartments flag to
assign each dot to the poles (2), bottom center (1) or top center (0)
compartments. The pole compartments are defined as the 20%% of the whole volume,
by cutting perpendicularly to the major axis. Information on goodnes of fit is
reported and a plot is provided with each nucleus rotated and centered. Plotting
can be turned off generally with the --noplot flag, and specifically with the
--no-compartment-plot flag.
''', formatter_class = argparse.RawDescriptionHelpFormatter)

# Add mandatory arguments
parser.add_argument('dotCoords', type = str, nargs = 1,
	help = 'Dot coordinates table generated by DOTTER.')
parser.add_argument('imgFolder', type = str, nargs = 1,
	help = 'Path to folder containing deconvolved tiff images.')
parser.add_argument('outFolder', type = str, nargs = 1,
	help = 'Path to output folder (created if does not exist).')

# Optional parameters
parser.add_argument('-a', '--aspect', type = float, nargs = 3,
	help = """Physical size of Z, Y and X voxel sides.
	Default: 300.0 130.0 130.0""",
	metavar = ('Z', 'Y', 'X'), default = [300., 130., 130.])
parser.add_argument('-d', '--delim', metavar = "sep", type = str, nargs = 1,
	help = """Input table delimiter. Default: ','""", default = [','])
parser.add_argument('-D', '--dilate', metavar = "npx", type = int, nargs = 1,
	help = """Number of pixels for nuclear mask dilation. It is automatically
	scaled based on the specified aspect to be isotropic in 3D. Default: 0""",
	default = [0])
parser.add_argument('-t', '--threads', metavar = "nthreads", type = int,
	help = """Number of threads for parallelization. Default: 1""",
	default = [1], nargs = 1)
parser.add_argument('-m', '--mask-folder', metavar = "folder", type = str,
	help = """Path to folder containing binarized/labeled images.
	Masks will be saved to this folder if missing.""",
	default = [None], nargs = 1)
parser.add_argument('-M', '--mask-prefix', metavar = "prefix", type = str,
	help = """Prefix for mask selection. Default: 'mask_'.""",
	default = ["mask_"], nargs = 1)
parser.add_argument('-P', '--pole', metavar = "axis_fraction", type = int,
	help = """Fraction of the major nuclear axis to identify a pole.
	Should be in the [0, .5] interval. Default: .25.""",
	default = [.25], nargs = 1)

# Add flags
parser.add_argument('--labeled',
    action = 'store_const', dest = 'labeled',
    const = True, default = False,
    help = 'Export labeled masks instead of binary.')
parser.add_argument('--compressed',
    action = 'store_const', dest = 'compressed',
    const = True, default = False,
    help = 'Generate compressed TIF binary masks (not compatible with ImageJ.')
parser.add_argument('--annotate-compart', action = 'store_const',
	dest = 'do_annotate_compartments', const = True, default = False,
	help = 'Assign dots to nuclear compartments, only for ellipsoidal nuclei.')
parser.add_argument('--noplot',
	action = 'store_const', dest = 'noplot',
	const = True, default = False,
	help = 'Do not produce any plots.')
parser.add_argument('--no-compart-plot', action = 'store_const',
	dest = 'no_compartment_plot', const = True, default = False,
	help = 'Do not produce compartments-related plots.')

# Version flag
version = "4.1.4"
parser.add_argument('--version', action = 'version',
	version = '%s v%s' % (sys.argv[0], version,))

# Parse arguments
args = parser.parse_args()

# Assign to in-script variables
dot_table_name = args.dotCoords[0]
dot_file_name = dot_table_name.split('/')[-1]

imdir = args.imgFolder[0]
outdir = args.outFolder[0]
delim = args.delim[0]

aspect = args.aspect
(az, ay, ax) = aspect

mask_iodir = args.mask_folder[0]
maskpre = args.mask_prefix[0]

doCompartments = args.do_annotate_compartments
pole_fraction = args.pole[0]
noplot = args.noplot
noplot_compartments = args.no_compartment_plot

labeled = args.labeled
compressed = args.compressed

dilate_factor = args.dilate[0]
ncores = args.threads[0]

# Params
seg_type = gp.const.SEG_3D
an_type = gp.const.AN_3D

# Additional checks ------------------------------------------------------------
if not outdir[-1] == "/":
	while not os.path.isdir(outdir) and os.path.exists(outdir): outdir += "_"
	outdir += "/"
if not imdir[-1] in ['/\\']: imdir += "/"
maxncores = multiprocessing.cpu_count()
if maxncores < ncores:
	print("Lowered number of threads to maximum available: %d" % (maxncores))
	ncores = maxncores
if 0 != dilate_factor and ax != ay:
	print("Cannot apply dilation on images with different X/Y aspect.")
	sys.exit()
if 0 > pole_fraction: pole_fraction = 0
if 0.5 < pole_fraction: pole_fraction = 0.5

# FUNCTIONS ====================================================================

def mkIsoStruct(dilate_factor, aspect):
	'''
	Builds isotropic structuring element for dilation.
	
	Args:
	  dilate_factor (int): number of px for isotropic 2D dilation.
	  aspect (tuple(float)): voxel side ratios.
	
	Returns:
	  np.ndarray: structureing element for 3D anisotropic dilation.
	'''
	
	# Dilation factors
	df_xy = int(dilate_factor * 2 + 1)
	df_z = int(dilate_factor * aspect[1] / aspect[0] * 2 + 1)

	if df_z == df_xy:
		# Isotropic
		return(cube(df_z))
	elif df_z > df_xy:
		# Larger Z side
		se = cube(df_z)
		se = se[:, 0:df_xy, 0:df_xy]
	else:
		# Larger XY side
		se = cube(df_xy)
		se = se[0:df_z]

	# Output
	return(se)

def in_mask(coords, imbin):
	'''Check if a pixel in a mask is foreground.'''
	
	# Check the pixel is inside the image boundaries
	inbound = imbin.shape[0] > coords[0]
	inbound = inbound and imbin.shape[1] > coords[1]
	inbound = inbound and imbin.shape[2] > coords[2]
	inbound = inbound and all(np.array(coords) >= 0)
	if not inbound:
		return(False)

	# Check the pixel is foreground
	return(1 == imbin[coords[0], coords[1], coords[2]])

def save_mask_png(outpath, im, name, title):
	'''
	Export png of an image.

	Args:
	Returns:
	'''
	fig = plt.figure()
	if 3 == len(im.shape):
		plt.imshow(im.max(0).astype('u4'))
	else:
		plt.imshow(im.astype('u4'))
	plt.gca().get_xaxis().set_visible(False)
	plt.gca().get_yaxis().set_visible(False)
	plot.set_font_size(8)

	plt.title(title)

	# Export as png
	if not noplot: plot.export(outpath, 'png')

	# Close plot figure
	plt.close(fig)

def in_3d_box(box, coords):
	'''
	Check if point is in a box

	Args:
	  box (tuple): ((x0, x1), (y0, y1), (z0, z1)).
	  coords (tuple): (x, y, z).

	Returns
	  bool
	'''
	cx = coords[0] >= box[0][0] and coords[0] <= box[0][1]
	cy = coords[1] >= box[1][0] and coords[1] <= box[1][1]
	cz = coords[2] >= box[2][0] and coords[2] <= box[2][1]
	return(cx and cy and cz)

def build_nuclei(msg, L, dilate_factor, series_id, thr, dna_bg, sig_bg,
	aspect, offset, logpath, i):
	'''
	Build nuclei objects
	
	Args:
	  msg (string): log message, to be continued.
	  L (np.ndarray): labeled mask.
	  dilate_factor (int): dilation factor.
	  series_id (int): series ID.
	  thr (float): global threshold value.
	  dna_bg (float): DNA channel background.
	  sig_bg (float): signal channel background.
	  aspect (tuple): Z,Y,X voxel sides in real units.
	  offset (tuple): tuple with pixel offset for bounding box.
	  logpath (string): path to log file.
	  i (np.array): image.
	
	Returns:
	  (string, list): log message and list of Nucleus objects.
	'''
	
	# Prepare input for Nucleus class
	kwargs = {
		'series_id' : series_id, 'thr' : thr,
		'dna_bg' : dna_bg, 'sig_bg' : sig_bg,
		'aspect' : aspect, 'offset' : offset,
		'logpath' : logpath, 'i' : i
	}

	# Default nuclear ID list and empty dictionary
	seq = range(1, L.max() + 1)
	curnuclei = {}

	# Log operation
	if 0 != dilate_factor:
		msg += "   - Saving %d nuclei with dilation [%d]...\n" % (
			L.max(), dilate_factor)
	else:
		msg += "   - Saving %d nuclei...\n" % (L.max(),)

	# Iterate through nuclei
	for n in seq:
		# Make nucleus
		if 0 != dilate_factor:
			# With dilated mask
			mask = dilation(L == n, istruct)
			nucleus = Nucleus(n = n, mask = mask, **kwargs)
		else:
			mask = L == n
			nucleus = Nucleus(n = n, mask = mask, **kwargs)

		# Apply box
		msg += "    > Applying nuclear box [%d]...\n" % (n,)
		mask = imt.apply_box(mask, nucleus.box)

		# Store nucleus
		nucleus.mask = mask
		nucleus.box_origin = np.array([c[0] + 1 for c in nucleus.box])
		nucleus.box_sides = np.array([np.diff(c) for c in nucleus.box])
		nucleus.box_mass_center = center_of_mass(mask)
		nucleus.dilate_factor = dilate_factor
		curnuclei[n] = nucleus

	return((msg, curnuclei))

def dots2cells(t, nuclei, dilate_factor):
	'''
	Assign dots to cells
	
	Args:
	  t (pd.DataFrame): DOTTER output subset.
	  nuclei (list(gp.Nucleus)): identified nuclei.
	  dilate_factor (int): number of dilation operations.
	
	Returns:
	  pd.DataFrame: updated DOTTER output.
	'''
	
	for idx in t.index:
		coords = ( t.loc[idx, 'z'], t.loc[idx, 'x'], t.loc[idx, 'y'] )
		for (nid, n) in nuclei.items():
			if in_mask(coords - n.box_origin, n.mask):
				t.loc[idx, 'cell_ID'] = nid
				continue

	# Output
	return(t)

def calc_dot_distances(msg, t, nuclei, aspect):
	'''
	Calculate distance of dots from lamina and central area
	
	Args:
	  msg (string): log message, to be continued.
	  t (pd.DataFrame): DOTTER output table.
	  nuclei (list(gp.Nucleus)): identified nuclei.
	  aspect (tuple): Z,Y,X voxel sides in real units.
	
	Returns:
	  pd.DataFrame: updated dotter table.
	  str: message log..
	'''

	# Skip if no cells are present
	if ( np.all(np.isnan(t['cell_ID'])) ):
		return((t, msg))

	# Calculate distances ------------------------------------------------------
	for cid in range(int(np.nanmax(t['cell_ID'])) + 1):
		if cid in nuclei.keys():
				msg += "    >>> Working on cell #%d...\n" % (cid,)
				cell_cond = cid == t['cell_ID']

				# Distance from lamina and center
				laminD = distance_transform_edt(nuclei[cid].mask, aspect)
				centrD = distance_transform_edt(laminD != laminD.max(), aspect)

				t.loc[cell_cond, 'lamin_dist'] = laminD[
					t.loc[cell_cond, 'z'] - nuclei[cid].box_origin[0],
					t.loc[cell_cond, 'x'] - nuclei[cid].box_origin[1],
					t.loc[cell_cond, 'y'] - nuclei[cid].box_origin[2]
				]

				t.loc[cell_cond, 'centr_dist'] = centrD[
					t.loc[cell_cond, 'z'] - nuclei[cid].box_origin[0],
					t.loc[cell_cond, 'x'] - nuclei[cid].box_origin[1],
					t.loc[cell_cond, 'y'] - nuclei[cid].box_origin[2]
				]

	# Normalize distances ------------------------------------------------------

	# Max distance for each dot
	fnorm = t.loc[:, 'lamin_dist'] + t.loc[:, 'centr_dist']
	t.loc[:, 'centr_dist_norm'] = t.loc[:, 'centr_dist'] / fnorm
	t.loc[:, 'lamin_dist_norm'] = t.loc[:, 'lamin_dist'] / fnorm

	# Output
	return((t, msg))

def centered_coords_3d(img, dot_coords = None):
	'''
	Extract coordinates from binary image and center them on the origin.

	Args:
		img (nd.array): binary image.
	'''
	z, x, y = np.nonzero(img)

	if not type(None) == type(dot_coords):
		zd, xd, yd = dot_coords
		xd = xd - np.mean(x)
		yd = yd - np.mean(y)
		zd = zd - np.mean(z)

	x = x - np.mean(x)
	y = y - np.mean(y)
	z = z - np.mean(z)

	if not type(None) == type(dot_coords):
		return((x, y, z, xd, yd, zd))
	else:
		return((x, y, z, None, None, None))

def extract_3ev(coords):
	'''
	Extract 3 major eigen vectors.

	Args:
		coords (nd.array): coordinates table with one point per row.

	Returns:
		tuple: major 3 eigen vectors. Coordinate order matches input columns.
	'''

	cov = np.cov(coords)
	evals, evecs = np.linalg.eig(cov)

	sort_indices = np.argsort(evals)[::-1]
	a_v1, b_v1, c_v1 = evecs[:, sort_indices[0]]
	a_v2, b_v2, c_v2 = evecs[:, sort_indices[1]]
	a_v3, b_v3, c_v3 = evecs[:, sort_indices[2]]

	av = [a_v1, a_v2, a_v3]
	bv = [b_v1, b_v2, b_v3]
	cv = [c_v1, c_v2, c_v3]

	return((av, bv, cv))

def rotate3d(coords, theta, axis):
	'''
	Rotate coordinates around an axis.

	Args:
		coords (nd.array): coordinate table.
		theta (float): rotation angle.
		axis (int): rotation axis, axis order matches coordinate columns.

	Returns:
		tuple: rotated coordinates.
	'''

	rotation_mat = False

	if 0 == axis: # X axis rotation
		rotation_mat = np.matrix([
			[1, 0, 0],
			[0, np.cos(theta), -np.sin(theta)],
			[0, np.sin(theta), np.cos(theta)]
		])

	if 1 == axis: # Y axis rotation
		rotation_mat = np.matrix([
			[np.cos(theta), 0, np.sin(theta)],
			[0, 1, 0],
			[-np.sin(theta), 0, np.cos(theta)]
		])

	if 2 == axis: # Z axis rotation
		rotation_mat = np.matrix([
			[np.cos(theta), -np.sin(theta), 0],
			[np.sin(theta), np.cos(theta), 0],
			[0, 0, 1]
		])

	if axis < 0  or axis > 2: # Unrecognized axis
		return()

	transformed_mat = rotation_mat * coords
	a, b, c = transformed_mat.A

	return((a, b, c))

def ortho_3d(coords, scale = None, dot_coords = None, c = None):
	'''
	Plot orthogonal projections with 3 major eigenvectors.

	Args:
		coords (nd.array): coordinate table with x, y, z columns.
		scale (int): size of plotted eigenvectors.
	'''

	if type(None) == type(scale):
		scale = 100

	plt.figure(figsize = (10, 10))

	x, y, z = coords
	xv, yv, zv = extract_3ev(coords)

	plt.subplot(2, 2, 1)
	plt.plot([xv[0]*-scale*3, xv[0]*scale*3],
	         [yv[0]*-scale*3, yv[0]*scale*3], color='r')
	plt.plot([xv[1]*-scale*2, xv[1]*scale*2],
	         [yv[1]*-scale*2, yv[1]*scale*2], color='b')
	plt.plot([xv[2]*-scale, xv[2]*scale],
	         [yv[2]*-scale, yv[2]*scale], color='g')
	plt.plot(x, y, 'k.', alpha = .05)
	plt.xlim(-300, 300)
	plt.ylim(-300, 300)
	plt.xlabel("X")
	plt.ylabel("Y")

	if not type(None) == type(dot_coords):
		plt.plot(dot_coords[0], dot_coords[1], 'r.')
	if not type(None) == type(c):
		plt.axvline(c, color = 'g', linestyle = ":")
		plt.axvline(-c, color = 'g', linestyle = ":")

	plt.subplot(2, 2, 2)
	plt.plot([zv[0]*-scale*3, zv[0]*scale*3],
	         [yv[0]*-scale*3, yv[0]*scale*3], color='r')
	plt.plot([zv[1]*-scale*2, zv[1]*scale*2],
	         [yv[1]*-scale*2, yv[1]*scale*2], color='b')
	plt.plot([zv[2]*-scale, zv[2]*scale],
	         [yv[2]*-scale, yv[2]*scale], color='g')
	plt.plot(z, y, 'k.', alpha = .05)
	plt.xlim(-300, 300)
	plt.ylim(-300, 300)
	plt.xlabel("Z")
	plt.ylabel("Y")

	if not type(None) == type(dot_coords):
		plt.plot(dot_coords[2], dot_coords[1], 'r.')
	if not type(None) == type(c):
		plt.axvline(0, color = 'b', linestyle = ":")

	plt.subplot(2, 2, 3)
	plt.plot([xv[0]*-scale*3, xv[0]*scale*3],
	         [zv[0]*-scale*3, zv[0]*scale*3], color='r')
	plt.plot([xv[1]*-scale*2, xv[1]*scale*2],
	         [zv[1]*-scale*2, zv[1]*scale*2], color='b')
	plt.plot([xv[2]*-scale, xv[2]*scale],
	         [zv[2]*-scale, zv[2]*scale], color='g')
	plt.plot(x, z, 'k.', alpha = .05)
	plt.xlim(-300, 300)
	plt.ylim(-300, 300)
	plt.xlabel("X")
	plt.ylabel("Z")

	if not type(None) == type(dot_coords):
		plt.plot(dot_coords[0], dot_coords[2], 'r.')
	if not type(None) == type(c):
		plt.axhline(0, color = 'b', linestyle = ":")
		plt.axvline(c, color = 'g', linestyle = ":")
		plt.axvline(-c, color = 'g', linestyle = ":")

	gline = mlines.Line2D([], [], color='g', label='ev3')
	bline = mlines.Line2D([], [], color='b', label='ev2')
	rline = mlines.Line2D([], [], color='r', label='ev1')
	plt.legend(handles = [gline, bline, rline])

def calc_theta(a, b):
	'''
	Calculate rotation angle based on a (opposite) and b (adjacent) sides.

	Return:
		float: theta in rad.
	'''
	c = np.sqrt(a**2 + b**2)
	if a > 0 and b < 0:
		return(np.arccos(a / c))
	elif a < 0 and b > 0:
		return(-np.arccos(a / c))
	elif a < 0 and b < 0:
		return(np.arccos(a / c))
	else:
		return(-np.arccos(a / c))

def annotate_compartments(msg, t, nuclei, outdir):
	'''
	Add compartment status to dots table (by DOTTER).
	For each nucleus: the major three axes are identified, the nucleus is
	centered and rotated. Then, the dots are also centered and rotated,
	and assigned to different compartments based on the fitted ellipsoid.
	Information on the goodness of ellipsoid fit is added to the main log and
	can be extracted by grepping lines starting with "   >>>> GoF_ellipse:".

	Args:
	   t (pd.DataFrame): DOTTER output table.
	   msg (string): log message, to be continued.

	Returns:

	'''

	# Temporarily remove dots outside cells
	nan_cond = np.isnan(t.loc[:, 'cell_ID'])
	vcomp_table = pd.DataFrame()

	subt = t.loc[np.logical_not(nan_cond), :].copy()
	if 0 == subt.shape[0]:
		print("!WARNING! All dots in FoV#%d are outside cells." % (
			t['File'].values[0],))
		return((t, vcomp_table, msg))

	fid = subt['File'].values[0]
	
	# Create empty table to host compartment volume data
	vcomp_table = pd.DataFrame(index = range(1, int(subt['cell_ID'].max()) + 1))
	vcomp_table['File'] = fid
	vcomp_table['cell_ID'] = range(1, int(subt['cell_ID'].max()) + 1)
	vcomp_table['center_bot'] = np.nan
	vcomp_table['center_top'] = np.nan
	vcomp_table['poles'] = np.nan
	vcomp_table['ndots_center_bot'] = np.nan
	vcomp_table['ndots_center_top'] = np.nan
	vcomp_table['ndots_poles'] = np.nan

	for cid in range(int(subt['cell_ID'].max()) + 1):
		if cid in nuclei.keys():
			msg += "    >>> Working on cell #%d...\n" % (cid,)
			cell_cond = cid == subt['cell_ID']

			# Extract dots coordinates -----------------------------------------
			dot_coords = np.vstack([
				subt.loc[cell_cond, 'z'] - nuclei[cid].box_origin[0],
				subt.loc[cell_cond, 'x'] - nuclei[cid].box_origin[1],
				subt.loc[cell_cond, 'y'] - nuclei[cid].box_origin[2]
			])

			# Center coordinates -----------------------------------------------
			x, y, z, xd, yd, zd = centered_coords_3d(
				nuclei[cid].mask, dot_coords)
			coords = np.vstack([x, y, z])
			dot_coords = np.vstack([xd, yd, zd])

			# Rotate data ------------------------------------------------------
			
			# First axis
			xv, yv, zv = extract_3ev(coords)
			theta1 = calc_theta(xv[0], yv[0])
			xt, yt, zt = rotate3d(coords, theta1, 2)
			tcoords = np.vstack([xt, yt, zt])

			# Third axis
			xv, yv, zv = extract_3ev(tcoords)
			theta3 = calc_theta(xv[2], zv[2])
			if np.abs(theta3) > np.pi / 2.:
				if theta3 > 0:
					theta3 = -np.abs(theta3 - np.pi / 2.)
				else:
					theta3 = np.abs(theta3 + np.pi / 2.)
			else:
				theta3 = -np.abs(theta3 + np.pi / 2.)
			xt, yt, zt = rotate3d(tcoords, theta3, 1)
			tcoords = np.vstack([xt, yt, zt])

			# Second axis
			xv, yv, zv = extract_3ev(tcoords)
			theta2 = calc_theta(yv[1], zv[1])
			xt, yt, zt = rotate3d(tcoords, theta2, 0)
			tcoords = np.vstack([xt, yt, zt])

			# Fit ellipsoid ----------------------------------------------------

			# Round up rotated coordinates
			trcoords = tcoords.astype('i')

			# Convert to rotated image
			icoords = np.transpose(trcoords) + abs(trcoords.min(1))
			trbin = np.zeros((icoords.max(0) + 1).tolist()[::-1])
			trbin[icoords[:, 2], icoords[:, 1], icoords[:, 0]] = 1

			# Calculate axes size
			zax_size, xax_size, yax_size = trbin.shape

			el = draw.ellipsoid(zax_size / 2., xax_size / 2., yax_size / 2.)
			el = el[2:(zax_size + 2), 1:(xax_size + 1), 1:(yax_size + 1)]

			# Calculate intersection with fitting ellipsoid
			inter_size = np.logical_and(trbin, el).sum()

			# Log intersection
			comments = []
			comments.append("%s%%%s [%s.%s]." % (
				round(inter_size / float(trbin.sum()) * 100, 2,),
				" of the nucleus is in the ellipsoid", fid, cid,))
			comments.append("%s%%%s [%s.%s]." % (
				round(inter_size / float(el.sum()) * 100, 2,),
				" of the ellipsoid is in the nucleus", fid, cid,))
			msg += "".join(["   >>>> GoF_ellipse: %s\n" % (s,)
				for s in comments])

			# Identify ellipsoid foci
			b = xax_size / 2.
			a = yax_size / 2.
			c = np.sqrt(a**2 - b**2)
			#ecc = c / a

			# Rotate dots ------------------------------------------------------

			dot_coords_t = np.vstack(rotate3d(dot_coords, theta1, 2))
			dot_coords_t = np.vstack(rotate3d(dot_coords_t, theta2, 0))
			dot_coords_t = np.vstack(rotate3d(dot_coords_t, theta3, 1))

			# Assign compartments ----------------------------------------------
			# Compartment code:
			# 0 = center-top
			# 1 = center-bottom
			# 2 = pole
			cf = 1 - 2 * pole_fraction
			status = np.zeros(dot_coords.shape[1])
			status[dot_coords_t[2] < 0] = 1
			status[dot_coords_t[0] > cf * a] = 2
			status[dot_coords_t[0] < -(cf * a)] = 2
			subt.loc[cell_cond, 'compartment'] = status

			# Calculate compartment volume -------------------------------------

			# Round up coordinates
			xt = xt.astype('i')
			zt = zt.astype('i')

			# Count voxels in compartments
			vpole = sum(xt > c) + sum(xt < -c)
			centr_cond = np.logical_and(xt < c, xt > -c)
			vctop = np.logical_and(centr_cond, zt >= 0).sum()
			vcbot = np.logical_and(centr_cond, zt < 0).sum()

			vcomp_table.loc[cid, 'center_top'] = vctop
			vcomp_table.loc[cid, 'center_bot'] = vcbot
			vcomp_table.loc[cid, 'poles'] = vpole
			vcomp_table.loc[cid, 'ndots_center_top'] = (status == 0).sum()
			vcomp_table.loc[cid, 'ndots_center_bot'] = (status == 1).sum()
			vcomp_table.loc[cid, 'ndots_poles'] = (status == 2).sum()

			# Assign volume information
			volume = np.zeros(dot_coords.shape[1])
			volume[:] = vctop
			volume[dot_coords_t[2] < 0] = vcbot
			volume[dot_coords_t[1] > 2 * c - a] = vpole
			volume[dot_coords_t[1] < -(2 * c - a)] = vpole
			subt.loc[cell_cond, 'compartment_volume'] = volume

			# Generate compartment plot with dots ------------------------------
			
			if not type(None) == type(outdir):
				outpng = open(os.path.join(outdir,
					"%s.%s.png" % (fid, cid,)), "w+")
				plt.close("all")
				ortho_3d(tcoords, dot_coords = dot_coords_t, c = a * 0.6)
				plt.suptitle("\n".join(comments))
				plt.savefig(outpng, format = "png")
				plt.close("all")
				outpng.close()

			t.loc[np.logical_not(nan_cond), :] = subt

	return((t, vcomp_table, msg))

def flag_G1_cells(t, nuclei, outdir, dilate_factor, dot_file_name):
	'''
	Assign a binary flag identifying the predominant cell population
	based on flatten size and intensity sum
	
	Args:
	  t (pd.DataFrame): DOTTER output table.
	  nuclei (list(gp.Nucleus)): identified nuclei.
	  outdir (string): path to output folder.
	  dilate_factor (int): number of dilation operations.
	  dot_file_name (string): output file name.
	
	Returns:
	  pd.DataFrame:.
	'''
	
	print("> Flagging G1 cells...")

	# Retrieve nuclei summaries ------------------------------------------------
	print('   > Retrieving nuclear summary...')
	summary = np.zeros(len(nuclei),
		dtype = gp.const.DTYPE_NUCLEAR_SUMMARY)
	for i in range(len(nuclei)):
		summary[i] = nuclei[i].get_summary()

	# Filter nuclei ------------------------------------------------------------
	print('   > Filtering nuclei based on flatten size and intensity...')
	cond_name = 'none'
	sigma = .1
	nsf = (gp.const.NSEL_FLAT_SIZE, gp.const.NSEL_SUMI)
	out_dir = '.'

	# Filter features
	sel_data = {}
	ranges = {}
	plot_counter = 1
	for nsfi in nsf:
		# Identify Nuclear Selection Feature
		nsf_field = gp.const.NSEL_FIELDS[nsfi]
		nsf_name = gp.const.NSEL_NAMES[nsfi]
		print('   >> Filtering %s...' % (nsf_name,))

		# Start building output
		d = {'data' : summary[nsf_field]}

		# Calculate density
		d['density'] = stt.calc_density(d['data'], sigma = sigma)

		# Identify range
		args = [d['density']['x'], d['density']['y']]
		d['fwhm_range'] = stt.get_fwhm(*args)
		ranges[nsf_name] = d['fwhm_range']

		# Plot
		sel_data[nsf_field] = d

	# Select based on range
	f = lambda x, r: x >= r[0] and x <= r[1]
	for nsfi in nsf:
		nsf_field = gp.const.NSEL_FIELDS[nsfi]
		nsf_name = gp.const.NSEL_NAMES[nsfi]
		print("   > Selecting range for %s ..." % (nsf_name,))

		# Identify nuclei in the FWHM range
		nsf_data = sel_data[nsf_field]
		nsf_data['sel'] = [f(i, nsf_data['fwhm_range'])
			for i in nsf_data['data']]
		sel_data[nsf_field] = nsf_data

	# Select those in every FWHM range
	print("   > Applying selection criteria")
	nsfields = [gp.const.NSEL_FIELDS[nsfi] for nsfi in nsf]
	selected = [sel_data[f]['sel'] for f in nsfields]
	g = lambda i: all([sel[i] for sel in selected])
	selected = [i for i in range(len(selected[0])) if g(i)]
	sub_data = np.array(summary[selected])

	# Identify selected nuclei objects
	sel_nuclei_labels = ["_%d.%d_" % (n, s)
		for (n, s) in sub_data[['s', 'n']]]
	sel_nucl = [n for n in nuclei
		if "_%d.%d_" % (n.s, n.n) in sel_nuclei_labels]

	# Check which dots are in which nucleus and update flag --------------------
	print("   > Matching DOTTER cells with GPSeq cells...")
	t['G1'] = 0
	t.loc[np.where(np.isnan(t['cell_ID']))[0], 'G1'] = np.nan
	t['universalID'] =  ["_%s.%s_" % x for x in zip(
		t['File'].values, t['cell_ID'].values
	)]
	g1ids = [i for i in range(t.shape[0])
		if t.loc[i, 'universalID'] in sel_nuclei_labels]
	t.loc[g1ids, 'G1'] = 1
	t = t.drop('universalID', 1)

	# Add G1 status to summary -------------------------------------------------
	summary = pd.DataFrame(summary)
	summary['G1'] = np.zeros((summary.shape[0],))
	summary['universalID'] =  ["_%s.%s_" % x
		for x in zip(summary['s'].values, summary['n'].astype("f").values)]
	g1ids = [i for i in range(summary.shape[0])
		if summary.loc[i, 'universalID'] in sel_nuclei_labels]
	summary.loc[g1ids, 'G1'] = 1
	summary = summary.drop('universalID', 1)

	# Estimate radius ----------------------------------------------------------
	summary['sphere_radius'] = summary['size'].values * 3 / (4 * math.pi)
	summary['sphere_radius'] = (summary['sphere_radius'])**(1/3.)

	# Export -------------------------------------------------------------------

	# Export feature ranges
	s = ""
	for (k, v) in ranges.items():
		s += "%s\t%f\t%f\n" % (k, v[0], v[1])
	f = open("%s/feature_ranges.txt" % (outdir,), "w+")
	f.write(s)
	f.close()

	# Export summary
	outname = "%s/nuclei.out.dilate%d.%s" % (
		outdir, dilate_factor, dot_file_name)
	summary.to_csv(outname, sep = '\t', index = False)

	# Output -------------------------------------------------------------------
	print("> Flagged G1 cells...")
	return(t)

def add_allele(data):
	'''
	Add allele labels to DOTTER-based table with GPSeq-like centrality.
	
	Labels:
	  NaN : dot outside of cells.
	  -1  : more than 2 dots per cell.
	  0   : less than 2 dots per cell.
	  1   : central dot.
	  2   : peripheral dot.
	
	Args:
	  data (pd.DataFrame): DOTTER-based table with GPSeq-like centrality.
						   Required columns:
							  cell_ID, lamin_dist_norm, File, Channel
		Returns:
	  pd.DataFrame: input data table with added Allele column (label).
	'''

	# Initial checks -----------------------------------------------------------

	# Check that the format corresponds
	if not type(data) == type(pd.DataFrame()):
		print("Input should be a DataFrame from the pandas library.")
		return(data)

	# Check that required columns are present
	req_cols = ['cell_ID', 'lamin_dist_norm', 'File', 'Channel']
	check_cols = [True for c in req_cols if c in data.columns.tolist()]
	if not all(check_cols):
		miss_cols = [req_cols[i]
			for i in range(len(req_cols)) if not check_cols[i]]
		print("Some required columns are missing: %s" % (", ".join(miss_cols),))
		return(data)

	# Universal index and dots in cells ----------------------------------------

	# Default value of np.nan for dots outside of nuclei
	data['Allele'] = np.nan

	# Identify dots within cells
	validIdx = np.where(np.logical_not(np.isnan(data['cell_ID'])))[0]
	subt = data.loc[validIdx, :]

	# Assemble universal index
	subt['universalID'] =  ["%s_%s_%s" % t for t in zip(
		subt['File'].values, subt['Channel'].values, subt['cell_ID'].values
	)]

	# Count dots per universalID
	uID,  uCount = np.unique(subt.loc[validIdx, 'universalID'],
		return_index = False, return_counts = True)
	IDmap = zip(subt.loc[validIdx, 'universalID'],
		[dict(zip(uID, uCount))[ID]
		for ID in subt.loc[validIdx, 'universalID']])
	IDmap = np.array(list(IDmap))
	
	# Stop if no dots are inside a cell
	if 0 == sum(IDmap.shape):
		return(data)

	# Fill Allele column -------------------------------------------------------

	# -1 if more than 2 dots
	cond = IDmap[:,1].astype('i') > 2
	if 0 != sum(cond):
		subt.loc[validIdx[cond], 'Allele'] = -1

	#  0 if less than 2 dots
	cond = IDmap[:,1].astype('i') == 1
	if 0 != sum(cond):
		subt.loc[validIdx[cond], 'Allele'] = 0

	# Iterate over 2-dots cases
	cond = IDmap[:,1].astype('i') == 2
	if 0 != sum(cond):
		uID = np.unique(IDmap[cond, 0]).tolist()
		for ID in uID:
			dotPair = subt.loc[subt['universalID'] == ID, :]
			ldn = dotPair['lamin_dist_norm'].tolist()
			if ldn[0] == ldn[1]:
				# Same centrality
				subt.loc[dotPair.index[0], 'Allele'] = 1 # Central
				subt.loc[dotPair.index[1], 'Allele'] = 2 # Peripheral
			else: # Different centrality
				# Peripheral
				subt.loc[dotPair['lamin_dist_norm'].argmin(), 'Allele'] = 2
				# Central
				subt.loc[dotPair['lamin_dist_norm'].argmax(), 'Allele'] = 1

	# Output -------------------------------------------------------------------
	data.loc[validIdx, 'Allele'] = subt['Allele']
	return(data)

def angle_between_points( p0, c, p1 ):
	'''
	c is the center point; result is in degrees
	From http://phrogz.net/angle-between-three-points
	'''
	p0 = np.array(p0)
	c = np.array(c)
	p1 = np.array(p1)

	p0c = np.sqrt(np.sum((p0 - c)**2))
	p1c = np.sqrt(np.sum((p1 - c)**2))
	p01 = np.sqrt(np.sum((p0 - p1)**2))

	tetha = math.acos( (p0c**2 + p1c**2 - p01**2) / (2 * p0c * p1c) )

	return(tetha / math.pi * 180)

def get_dtype(i):
    '''
    Identify bit depth for a matrix of maximum intensity i.
    '''
    depths = [1, 2, 4, 8, 16]
    for depth in depths:
        if i <= 2**depth-1:
            return("u%d" % (depth,))
    return("u")

def save_tif(path, img, dtype, compressed):
    new_shape = [1]
    [new_shape.append(n) for n in img.shape]
    img.shape = new_shape

    if compressed:
        tifffile.imsave(path, img.astype(dtype),
            shape = img.shape, compress = 9,
            dtype = dtype, imagej = True, metadata = {'axes' : 'CZYX'})
    else:
        tifffile.imsave(path, img.astype(dtype),
            shape = img.shape, compress = 0,
            dtype = dtype, imagej = True, metadata = {'axes' : 'CZYX'})

def analyze_field_of_view(ii, imfov, imdir, an_type, seg_type,
	maskdir, dilate_factor, aspect, t, main_mask_dir, main_mask_prefix,
	doCompartments, plotCompartments, outdir):
	
	# Logger for logpath
	logger = iot.IOinterface()

	idx = ii
	impath = imfov[ii]
	msg = "> Job '%s'...\n" % (impath,)
	subt_idx = np.where(t['File'] == idx)[0]

	# Read image
	msg += "   - Reading ...\n"
	im = tifffile.imread(os.path.join(imdir, impath))
	if 1 == im.shape[0]:
		im = im[0]

	# Re-slice
	msg += "    > Re-slicing ...\n"
	im = imt.autoselect_time_frame(im)
	im = imt.slice_k_d_img(im, 3)

	# Get DNA scaling factor and rescale
	sf = imt.get_rescaling_factor([impath], basedir = imdir)
	im = (im / sf).astype('float')
	msg += "    > Re-scaling with factor %f...\n" % (sf,)

	# Pick first timeframe
	if 3 == len(im.shape) and 1 == im.shape[0]:
		im = im[0]

	# Binarize image -----------------------------------------------------------
	binarization = gp.tools.binarize.Binarize(
		an_type = an_type, seg_type = seg_type, verbose = False)
	
	# Check if already segmented
	already_segmented = False
	if not type(None) == type(main_mask_dir):
		mpath = os.path.join(main_mask_dir, main_mask_prefix + impath)
		if os.path.isfile(mpath):
			already_segmented = True

	# Skip or binarize
	if already_segmented:
		msg += "   - Skipped binarization, using provided mask.\n"
		imbin = tifffile.imread(mpath) != 0
		thr = 0
	else:
		msg += "   - Binarizing...\n"
		(imbin, thr, log) = binarization.run(im)
		if not type(None) == type(main_mask_dir):
			if os.path.isdir(main_mask_dir):
				msg += "   >>> Exporting mask as tif...\n"
				if labeled:
					save_tif(mpath, label(imbin), 'uint8', compressed)
				else:
					save_tif(mpath, imbin, 'uint8', compressed)
		msg += log

	# Find nuclei --------------------------------------------------------------
	msg += "   - Retrieving nuclei...\n"

	# Estimate background
	dna_bg = imt.estimate_background(im, imbin, seg_type)
	msg += "    > Estimated background: %.2f a.u.\n" % (dna_bg,)

	# Filter object size
	imbin, tmp = binarization.filter_obj_XY_size(imbin)
	imbin, tmp = binarization.filter_obj_Z_size(imbin)

	# Save default mask
	msg += "   - Saving default binary mask...\n"
	outname = "%smask.%s.default.png" % (maskdir, os.path.splitext(impath)[0])
	save_mask_png(outname, imbin, impath, "Default mask.")

	# Export dilated mask
	if not noplot and 0 != dilate_factor:
		msg += "   - Saving dilated mask...\n"
		imbin_dil = dilation(imbin, istruct)
		title = "Dilated mask, %d factor." % (dilate_factor,)
		outname = "%smask.%s.dilated%d.png" % (maskdir,
			os.path.splitext(impath)[0], dilate_factor)
		save_mask_png(outname, imbin_dil, impath, title)

	# Identify nuclei
	L = label(imbin)
	seq = range(1, L.max() + 1)

	# Save mask ----------------------------------------------------------------
	msg += "   - Saving nuclear ID mask...\n"
	title = 'Nuclei in "%s" [%d objects]' % (impath, L.max())
	outpath = "%smask.%s.nuclei.png" % (maskdir, os.path.splitext(impath)[0])
	save_mask_png(outpath, L, impath, title)

	# Store nuclei -------------------------------------------------------------
	msg, curnuclei = build_nuclei(msg, L, dilate_factor,
		series_id = ii, thr = thr,
		dna_bg = dna_bg, sig_bg = 0,
		aspect = aspect, offset = (1, 1, 1),
		logpath = logger.logpath, i = im)

	# Assign dots to cells -----------------------------------------------------
	msg += "   - Analysis...\n"
	msg += "    > Assigning dots to cells...\n"
	subt = dots2cells(t.loc[subt_idx, :], curnuclei, dilate_factor)

	# Distances ----------------------------------------------------------------
	msg += "    > Calculating lamina distance...\n"
	subt, msg = calc_dot_distances(msg, subt, curnuclei, aspect)

	# Compartments -------------------------------------------------------------

	if doCompartments:
		msg += "    > Annotating compartments...\n"
		compdir = None

		if plotCompartments:
			# Create compartments output directory
			compdir = os.path.join(outdir, 'compartments/')
			if not os.path.isdir(compdir):
				os.mkdir(compdir)

		# Perform annotation
		subt, tvcomp, msg = annotate_compartments(msg, subt, curnuclei, compdir)
	else:
		msg += "    > Skipped compartments annotation.\n"

	# Clean and output ---------------------------------------------------------

	# Remove masks from curnuclei
	for k in curnuclei.keys():
		del curnuclei[k].mask

	# Output
	msg += "< Finished job.\n"
	#print(msg)
	return((curnuclei, subt, subt_idx, tvcomp, msg))

# RUN ==========================================================================

# Create output folder
if not os.path.isdir(outdir):
	os.mkdir(outdir)

# Create mask directory
maskdir = outdir + "masks/"
if not os.path.isdir(maskdir):
	os.mkdir(maskdir)

# Build 3D isotropic structuring element for dilation
istruct = mkIsoStruct(dilate_factor, (az, ay, ax))
if az != ax:
	t = np.array(istruct.shape) / 2
	msg = "  Anisotropic dilation of "
	msg += "(%d, %d, %d) px in ZYX, respectively." % tuple(t.tolist())
	print(msg)

# Input ------------------------------------------------------------------------

# Read table
t = pd.read_csv(dot_table_name, delim)

# Add new empty columns
t['cell_ID'] = np.nan
t['lamin_dist'] = np.nan
t['lamin_dist_norm'] = np.nan
t['centr_dist'] = np.nan
t['centr_dist_norm'] = np.nan
t['com'] = np.nan
t['angle'] = np.nan
if doCompartments:
	t['compartment'] = np.nan
t['dilation'] = dilate_factor
t['version'] = version

# Identify images --------------------------------------------------------------

# Extract FoV number
t['File'] = [int(f.split('/')[-1].split('.')[0]) for f in t['File']]

# Round up coordinates !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! NEEDS TO BE CHANGED TO INTERPOLATE!
t['x'] = np.round(t['x']).astype('i')
t['y'] = np.round(t['y']).astype('i')
t['z'] = np.round(t['z']).astype('i')
# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

# Identify tiff images
flist = []
for (dirpath, dirnames, filenames) in os.walk(imdir):
	flist.extend(filenames)
	break
imlist = [f for f in flist if 'tif' in f]

# Assign field of views to images
imfov = {}
for i in set(t['File']):
	imsel = [im for im in imlist if "%03d" % (i,) in im]
	if not 0 == len(imsel):
		imfov[i] = imsel[0]
	else:
		t = t.ix[t["File"] != i, :]
		print("  Missing image for field #%d, skipped." % (i,))
t.index = range(t.shape[0])

# Start iteration --------------------------------------------------------------

# Nuclei container
nuclei = []

# Cycle through
print("> Analyzing fields of view... [n.threads=%d]" % (ncores,))
kwargs = {
	'imfov' : imfov, 'imdir' : imdir,
	'an_type' : an_type, 'seg_type' : seg_type, 'maskdir' : maskdir,
	'dilate_factor' : dilate_factor, 'aspect' : aspect, 't' : t,
	'main_mask_dir' : mask_iodir, 'main_mask_prefix' : maskpre,
	'doCompartments' : doCompartments,
	'plotCompartments' : not noplot_compartments, 'outdir' : outdir
}
anData = Parallel(n_jobs = ncores, verbose = 11)(
	delayed(analyze_field_of_view)(ii, **kwargs)
	for ii in set(imfov.keys()))

# Parse output and store log report --------------------------------------------

hlog = open(os.path.join(outdir, "fov_analysis.log"), "w+")
tvdata = []
for (curnuclei, subt, subt_idx, tvcomp, msg) in anData:
	nuclei.extend(curnuclei.values())
	t.loc[subt_idx, :] = subt
	hlog.write(msg)
	if doCompartments:
		tvdata.append(tvcomp)
hlog.close()


# Identify G1 cells ------------------------------------------------------------
t = flag_G1_cells(t, nuclei, outdir, dilate_factor, dot_file_name)

# Export -----------------------------------------------------------------------

# Export compartment volume data
if doCompartments:
	tvdata = pd.concat(tvdata)
	outname = "%s/nuclear_compartment.volume.tsv" % (outdir,)
	tvdata.to_csv(outname, sep = '\t', index = False)

# Export nuclei object vector
f = open("%s/nuclei.pickle" % (outdir,), "wb+")
pickle.dump(nuclei, f)
f.close()

# Export table before allele labeling
outname = "%s/wCentr.out.noAllele.dilate%d.%s" % (
	outdir, dilate_factor, dot_file_name)
t.to_csv(outname, sep = '\t', index = False)

# Add allele information -------------------------------------------------------
print("  - Adding allele information...")
t = add_allele(t)

# Calculate angle on nucleus centroid between alleles --------------------------
print("  - Adding allele polarity information...")

# Assemble universal index
t.loc[:, 'universalID'] = ["%s_%s_%s" % x for x in zip(
	t['File'].values, t['Channel'].values, t['cell_ID'].values
)]

# Subset data
subt = t.loc[t['Allele'] > 0,:]

# Go through cells
for uid in subt['universalID']:
	idx = subt[subt['universalID'] == uid].index

	# Retrieve allele coordinates
	focus = subt.loc[subt['universalID'] == uid, ('x', 'y', 'z')]
	if 0 == sum(focus.shape):
		continue

	# Identify nucleus
	cell_ID = subt.loc[subt['universalID'] == uid, 'cell_ID'].values[0]
	series_ID = subt.loc[subt['universalID'] == uid, 'File'].values[0]
	if np.isnan(cell_ID) or np.isnan(series_ID):
		continue

	nucleus = [n for n in nuclei if n.s == series_ID and n.n == cell_ID]
	if 0 == len(nucleus):
		print("Nucleus not found for %s.%s" % (series_ID, cell_ID,))
		continue
	else:
		nucleus = nucleus[0]

	# Nucleus center of mass coordinates
	centr_coords = (nucleus.box_mass_center + nucleus.box_origin).astype('i')
	
	# Re-order center of mass coordinates
	centr_coords = centr_coords[[1, 2, 0]]

	P1_coords = focus.loc[focus.index[0],:]
	P2_coords = focus.loc[focus.index[1],:]

	if all(P2_coords == centr_coords) or all(P1_coords == centr_coords):
		t.loc[idx, 'angle'] = 0
	else:
		# Calculate angle
		xyz_aspect = np.array((ax, ay, az))
		t.loc[idx, 'angle'] = angle_between_points(
			P1_coords * xyz_aspect,
			centr_coords * xyz_aspect,
			P2_coords * xyz_aspect
		)
	t.loc[idx, 'com'] = "_".join([str(x) for x in centr_coords.tolist()])

# Remove universal ID
t = t.drop('universalID', 1)

# Write output -----------------------------------------------------------------
outname = "%s/wCentr.out.dilate%d.%s" % (
	outdir, dilate_factor, dot_file_name)
t.to_csv(outname, sep = '\t', index = False)

# END ==========================================================================

################################################################################
